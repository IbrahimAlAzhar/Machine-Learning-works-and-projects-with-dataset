{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "#k nearest neighbour\n",
    "x = [[0],[1],[2],[3]]\n",
    "y = [0, 0, 1, 1]\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(x,y) #training the data\n",
    "print(neigh.predict([[1.1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.66666667 0.33333333]]\n"
     ]
    }
   ],
   "source": [
    "print(neigh.predict_proba([[0.9]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this whole code snippet for visualization the knn properly\n",
    "from matplotlib.colors import ListedColormap\n",
    "def knn_comparison(data,n_neighbors=15): #default n_neighbors is 15\n",
    "    #This function finds k-NN and plots the data\n",
    "    x = data[:,:2] #points\n",
    "    y = data[:,2] #class labels\n",
    "    #grid cell size\n",
    "    h = 0.2\n",
    "    cmap_light = ListedColormap('#FFAAAA','#AAAAFF') #set colors\n",
    "    cmap_bold = ListedColormap('#FF0000','#0000FF')\n",
    "    \n",
    "    # the core classifier : k-NN\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors) \n",
    "    clf.fit(x,y) #train the data\n",
    "    x_min, x_max = x[:,0].min()-1 , x[:,0].max()+1 #here create minimum and maximum values of x and y\n",
    "    y_min, y_max = x[:,1].min()-1, y[:,0].max()+1\n",
    "    #we create a mesh grid (x_min,y_min) to (x_max ,y_max) with 0.02 grid space\n",
    "    xx,yy = np.meshgrid(np.arrange(x_min,x_max,h), np.arrange(y_min,y_max,h)) # meshgrid creates a matrix from the range x_min to x_max and y_min to y_max\n",
    "    #we predict the value (either 0 or 1) of each element in the grid\n",
    "    z = clf.predict(np.c_[xx.ravel(),yy.ravel()])\n",
    "    #xx.ravel() will give a flatten array\n",
    "    #np.c_: Translates slice objects to concatenation along the second axis\n",
    "    #np.c_[np.array([1,2,3,4]), np.array([4,5,6,7])]\n",
    "    #array([[1,4],[2,5],[3,6],[4,7]])\n",
    "    # convert the out back to the xx shape\n",
    "    x = z.reshape(xx.shape)\n",
    "    #pcolormesh will plot the (xx,yy) grid with colors according to the values\n",
    "    #it looks like decision boundary\n",
    "    plt.figure()\n",
    "    plt.pcolormesh(xx,yy,z,cmap=cmap_light)\n",
    "    \n",
    "    #scatter plot of with given plots\n",
    "    plt.scatter(x[:,0],x[:,1],c=y,cmap=cmap_bold)\n",
    "    #definig scale on both axises\n",
    "    plt.xlim(xx.min(),xx.max())\n",
    "    plt.ylim(yy.min(),yy.max())\n",
    "    #set the title\n",
    "    plt.title('K value = '+str(n_neighbors))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genformtext('overlap.csv',delimiter=',')\n",
    "knn_comparison(data,1)\n",
    "knn_comparison(data,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1, data preprocessing\n",
    "#define column names\n",
    "names = ['x','y','class']\n",
    "#loading training data\n",
    "df = pd.read_csv('concertriccir2.csv',header=None,names=name)\n",
    "print(df.head())\n",
    "\n",
    "# create design matrix X and target vector Y\n",
    "x = np.array(df.iloc[:,0:4])\n",
    "y = np.array(df['class'])\n",
    "# split the data set into train and test \n",
    "x_1,x_test,y_1,y_test = cross_validation.train_test_split(x,y,test_size=0.3,random_state=42) # firstly we divide the dataset to x_1 and x_test,wher x_1 belongs to x_train and x_cv,only 30% data is using for test\n",
    "# split the train data set into cross validation train and cross validation test\n",
    "x_tr,x_cv,y_tr,y_cv = cross_validation.train_test_split(x_1,y_1,test_size=0.3) # now we divide the x_1 data to x_train and x_cv data set,only 30% data is using for cv\n",
    "\n",
    "for i in range(1,30,2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i) # take the neighbour is 1,3,5...29 etc\n",
    "    #fitting the model on crossvalidation train\n",
    "    knn.fit(x_tr,y_tr)\n",
    "    \n",
    "    #predict the response on the corssvalidation train\n",
    "    pred = knn.predict(x_cv)\n",
    "    \n",
    "    #evaluate cross validation accuracy, \n",
    "    acc = accuracy_score(y_cv,pred,normalize=True) * float(100) # 'y_cv' means orignal label of cross validation data,'pred' is predicted value of x_cv\n",
    "    print('\\nCV accuracy for k = %d is %d%%' % (i,acc))\n",
    "knn = KNeighborsClassifier(1) #here for test accuracy when k=1\n",
    "knn.fit(x_tr,y_tr) # fit the train data\n",
    "pred = knn.predict(x_test) # predict the test accuracy by x_test when k=1\n",
    "acc = accuracy_score(y_test,pred,normalize=True) * float(100)\n",
    "print('\\n**Test accuracy for k=1 is %d%%' % (acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 fold cross validation\n",
    "# creating odd list of K for KNN\n",
    "myList = list(range(0,50))\n",
    "neighbors = list(filter(lambda x: x %2 !=0,myList)) # the value stores in neighbors list is: 1,3,5,7...49\n",
    "\n",
    "#empty list what will hold cv scores\n",
    "cv_scores = []\n",
    "\n",
    "# perform 10-fold cross validation\n",
    "for k in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn,x_train,y_train,cv=10,scoring='accuracy') # applygin 10 fold cross validation and find out the scores\n",
    "    cv_scores.append(scores.mean()) # we take 10 values in scores using 10 fold cross validation,and we find out the mean value and append this value\n",
    "    \n",
    "#changing to misclassification error\n",
    "MSE = [1-x for x in cv_scores] # cv_scores is the value which measure the accuracy,so if we subtract the value from 1 then we find the error,which one store in MSE list\n",
    "# 0th index MSE value when k=1,1th index MSE value when k=3 etc\n",
    "#determining the best k\n",
    "optimal_k = neighbors[MSE.index(min(MSE))] #find out which one is minimum error, we take the min error value and find out the index number of 'MSE' list,whihc has same index number of 'neighbors' list(optimal k) \n",
    "print('\\nThe optimal number of neighbors is %d.' %optimal_k)\n",
    "\n",
    "#plot misclassification error vs K\n",
    "plt.plot(neighbors,MSE)\n",
    "\n",
    "for xy in zip(neighbors,np.round(MSE,3)):\n",
    "    plt.annotate('(%s, %s)' %xy, xy=xy,textcoords='data')\n",
    "\n",
    "plt.xlabel('Number of Neighbors K')\n",
    "plt.ylable('Misclassification Error')\n",
    "plt.show()\n",
    "print(\"The misclassification error for each k value is : \",np.round(MSE,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find out optimal k\n",
    "knn_optimal = KNeighborsClassifier(n_neighbors=optimal_k) # use the optimal_k as k\n",
    "#fitting the model\n",
    "knn_optimal.fit(x_train,y_train)\n",
    "\n",
    "#predict the response\n",
    "pred = knn_optimal.predict(x_test)\n",
    "\n",
    "#evaluate accuracy\n",
    "acc = accuracy_score(y_test,pred)*100\n",
    "print('\\nThe accuracy of the knn classifier for k=%d is %f%%' % (optimal_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Anaconda installation\\lib\\site-packages\\sklearn\\neighbors\\lof.py:236: FutureWarning: default contamination parameter 0.1 will change in version 0.22 to \"auto\". This will change the predict method behavior.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1,  1, -1,  1])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "X = [[-1.1],[0.2],[101.1],[0.3]]\n",
    "clf = LocalOutlierFactor(n_neighbors=2)\n",
    "clf.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.negative_outlier_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#naive bayes\n",
    "import numpy as np\n",
    "X = np.random.randint(2,size=(6,100)) # randomly choosen value 0 or 1 which one is 6 rows and 100 coloumns\n",
    "Y = np.array([1,2,3,4,4,5]) # predicted theses values(outputs)\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "clf = BernoulliNB()\n",
    "clf.fit(X, Y)\n",
    "clf.predict(X[0:2]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
